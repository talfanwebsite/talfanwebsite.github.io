---
layout: default
---

# About me

Iâ€™m currently a research scientist in the Machine Learning team at DeepMind. Recently, I've been interested in Active Data selection for data-efficient large scale model training and task alignment. I'm also interested in building better memory systems with / for generative models and using these for efficient / continual learning.

Previously, I was a postdoc at the Dyson Robotics Lab at Imperial College London, where I worked on real-time distributed inference and abstraction in spatial / visual perception systems.

Before that, I did a PhD in cognitive neuroscience at the Space and Memory Lab, University College London. I wrote my thesis on how the brain might implement distributed message passing algorithms to learn quickly from new data, which might look like "replaying" memories during sleep.

# Things that I'm thinking about (reach out to chat)

* How can we fundamentally re-imagine software / hardware in the age of large-scale generative models?
* How could we build smart materials that self-organize and compute like living tissue?
* Would "differentiable" materials be useful for robotics?
* How could we build a video game that incorporates fine-tuning / in-context learning as an element of gameplay?
* How can we build better simulators for molecular dynamics?
* What is the brain doing during sleep?
